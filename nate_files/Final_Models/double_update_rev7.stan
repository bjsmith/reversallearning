//rev7: Builds on rev6 (not rev6a). 
//      Introduces the LBA from Annis, Miller, & Palmeri (2017), which in turn closely follows Turner (2013).
//rev6: Builds on rev5a. Includes a parameter for reaction_time.
//reaction_time ranges from 0 to 1 (there are a few over 1).
//so if we simply multiply rt by inverse temperature
//inverse temperature would stand for a theoretical level existing at t=1;
//IT is "scaled down" for t<1.
//overall we will expect that in this new model, the IT term will be larger because it reflects a hypothetical
//performance if subjects were to wait.
//rev6: Builds on rev5a. Includes a parameter for reaction_time.
functions{
     
     real lba_pdf(real t, real b, real A, real v, real s){
          //PDF of the LBA model
          
          real b_A_tv_ts;
          real b_tv_ts;
          real term_1;
          real term_2;
          real term_3;
          real term_4;
          real pdf;
          
          b_A_tv_ts = (b - A - t*v)/(t*s);
          b_tv_ts = (b - t*v)/(t*s);
          term_1 = v*Phi(b_A_tv_ts);
          term_2 = s*exp(normal_lpdf(b_A_tv_ts | 0,1)); 
          term_3 = v*Phi(b_tv_ts);
          term_4 = s*exp(normal_lpdf(b_tv_ts | 0,1)); 
          pdf = (1/A)*(-term_1 + term_2 + term_3 - term_4);
          
          return pdf;
     }
     
     real lba_cdf(real t, real b, real A, real v, real s){
          //CDF of the LBA model
          
          real b_A_tv;
          real b_tv;
          real ts;
          real term_1;
          real term_2;
          real term_3;
          real term_4;
          real cdf;	
          
          b_A_tv = b - A - t*v;
          b_tv = b - t*v;
          ts = t*s;
          term_1 = b_A_tv/A * Phi(b_A_tv/ts);	
          term_2 = b_tv/A   * Phi(b_tv/ts);
          term_3 = ts/A     * exp(normal_lpdf(b_A_tv/ts | 0,1)); 
          term_4 = ts/A     * exp(normal_lpdf(b_tv/ts | 0,1)); 
          cdf = 1 + term_1 - term_2 + term_3 - term_4;
          
          return cdf;
          
     }
     
     //the relative threshold, k; 
     //the maximum starting evidence, A; 
     //a vector holding the drift rates, v; 
     //the standard deviation of the drift rates, s; 
     //and the nondecision time, tau.
     real lba_log(matrix RT, real k, real A, vector v, real s, real tau){
          
          real t;
          real b;
          real cdf;
          real pdf;		
          vector[rows(RT)] prob;
          real out;
          real prob_neg;

          b = A + k;
          for (i in 1:rows(RT)){	
               t = RT[i,1] - tau;
               if(t > 0){			
                    cdf = 1;
                    
                    for(j in 1:num_elements(v)){
                         if(RT[i,2] == j){
                              pdf = lba_pdf(t, b, A, v[j], s);
                         }else{	
                              cdf = (1-lba_cdf(t, b, A, v[j], s)) * cdf;
                         }
                    }
                    prob_neg = 1;
                    for(j in 1:num_elements(v)){
                         prob_neg = Phi(-v[j]/s) * prob_neg;    
                    }
                    prob[i] = pdf*cdf;		
                    prob[i] = prob[i]/(1-prob_neg);	
                    if(prob[i] < 1e-10){
                         prob[i] = 1e-10;				
                    }
                    
               }else{
                    prob[i] = 1e-10;			
               }		
          }
          out = sum(log(prob));
          if (is_nan(out)){
            print("matrix RT, real k, real A, vector v, real s, real tau")
            print(RT)
            print(k)
            print(A)
            print(v)
            print(s)
            print(tau)
          }
          return out;		
     }
     
    vector lba_rng(real k, real A, vector v, real s, real tau){
          
          int get_pos_drift;	
          int no_pos_drift;
          int get_first_pos;
          vector[num_elements(v)] drift;
          int max_iter;
          int iter;
          real start[num_elements(v)];
          real ttf[num_elements(v)];
          int resp[num_elements(v)];
          real rt;
          vector[2] pred;
          real b;
          
          //try to get a positive drift rate
          get_pos_drift = 1;
          no_pos_drift = 0;
          max_iter = 1000;
          iter = 0;
          while(get_pos_drift){
               for(j in 1:num_elements(v)){
                    drift[j] = normal_rng(v[j],s);
                    if(drift[j] > 0){
                         get_pos_drift = 0;
                    }
               }
               iter = iter + 1;
               if(iter > max_iter){
                    get_pos_drift = 0;
                    no_pos_drift = 1;
               }	
          }
          //if both drift rates are <= 0
          //return an infinite response time
          if(no_pos_drift){
               pred[1] = -1;
               pred[2] = -1;
          }else{
               b = A + k;
               for(i in 1:num_elements(v)){
                    //start time of each accumulator	
                    start[i] = uniform_rng(0,A);
                    //finish times
                    ttf[i] = (b-start[i])/drift[i];
               }
               //rt is the fastest accumulator finish time	
               //if one is negative get the positive drift
               resp = sort_indices_asc(ttf);
               ttf = sort_asc(ttf);
               get_first_pos = 1;
               iter = 1;
               while(get_first_pos){
                    if(ttf[iter] > 0){
                         pred[1] = ttf[iter] + tau;
                         pred[2] = resp[iter]; 
                         get_first_pos = 0;
                    }
                    iter = iter + 1;
               }
          }
          return pred;	
     }
}
data {
  int<lower=1> N;
  int<lower=1> T;
  int<lower=1,upper=T> Tsubj[N];
  int<lower=1,upper=100> N_cues[N];
  int<lower=0,upper=100> cue[N,T];
  int trial[N,T];
  int cue_pos[N,T];
  int subjid[N,T];
  int cor_resp[N,T];
  int cue_freq[N,T];
  real<lower=-1,upper=1> outcome[N,T];
  int sample_from_prior;
  //int subj_level_params;
  
  //multiple runs, multiple reward type extension
  int<lower=1> R; //number of runs (max)
  int<lower=1> R_N[N]; //number of runs for each subject
  int<lower=0> run_id[N,T];
  
  //run outcome type. Indicates whether a particular run is reward or punishment.
  int<lower=0> run_ot[N,R];
  
  //response time and choice
  real<lower=0,upper=2> rt[N,T];
  int<lower=0,upper=2> choice[N,T];
  
}
transformed data{
  int PID_ALPHA = 1;
  int PID_LBA_K = 2;
  int PID_LBA_TAU = 3;
  
  matrix[2,T] RT_choice[N];
  
  //column 1 is RT
  //column 2 is choice
  //lba requires this format.
  for (s in 1:N){
    for (t in 1:T){
      RT_choice[s,1,t]=rt[s,t];
      RT_choice[s,2,t]=choice[s,t];
    }
  }
  
}
parameters {
// Declare all parameters as vectors for vectorizing
  // Hyper(group)-parameters
  vector[3] group_pr_mu; //group-level means of subject means
  vector<lower=0>[3] group_pr_sigma; //variance within the group, across subjects
  
  //hypers for reward-punishment difference
  vector[2] group_pr_rpdiff_mu; //group-level means of subject means
  vector<lower=0>[2] group_pr_rpdiff_sigma; //variance within the group, across subjects
  
  // Subject-level raw parameters. 
  vector[N] alpha_s_pr_mu;   // learning rate, subject average across runs
  //vector[N] beta_s_pr_mu;  // inverse temperature, subject average across runs
  vector[N] lba_k_s_pr_mu;   // 
  vector[N] lba_tau_s_pr_mu;   // 
  vector[N] alpha_s_pr_rpdiff_mu;   // learning rate, difference between reward and punishment
  //vector[N] beta_s_pr_rpdiff_mu;  // inverse temperature, difference between reward and punishment
  vector[N] lba_k_s_pr_rpdiff_mu;   // 
    //Will be very important to somehow ignore values from subjects where there's no actual difference.

  //these are not vectors because we make a simplifying assumption they're the same for all subjects.
  real<lower=0> alpha_s_pr_sigma;   // learning rate, subject variance across runs
  //real<lower=0> beta_s_pr_sigma;  // inverse temperature, subject variance across runs
  real<lower=0> lba_k_s_pr_sigma;  //relative threshold
  real<lower=0> lba_tau_s_pr_sigma; //
  
  // Run level raw parameters
  // using probit transform
  real alpha_pr[N, R];   // learning rate, run estimate
  //real beta_pr[N, R];  // inverse temperature, run estimate
  real lba_k_pr[N, R];  // relative threshold
  real lba_tau_pr[N, R];  // indecision period
}

transformed parameters {
// here is where we take that normally distributed parameter 
// and phi-approximate it into a range.

  // Transform subject-level raw parameters
  real<lower=0,upper=1> alpha[N, R];
  //real<lower=0,upper=14> beta[N, R];
  real<lower=0,upper=14> lba_k[N, R];
  real<lower=0,upper=14> lba_tau[N, R];
  //interacts directly with the trial-level learning
  //drawn from a phi-approximation from group-level mean and deviation multiplied by subject-level parameter

  //run level parameter transform.
  //I am not sure if this is high enough. 
  //This is double what we found in the recent paper using the same model
  for (s in 1:N) {
    for (r in 1:R){
      alpha[s, r]  = Phi_approx( alpha_pr[s, r]);
      //beta[s, r]   = Phi_approx( beta_pr[s, r]) * 14; 
      lba_k[s ,r] = exp(lba_k_pr[s, r]);
      lba_tau[s ,r] = exp(lba_tau_pr[s, r]);
    }
  }
}

model {
  
  int run = -1; //an iterator
  real run_ot_multiplier =0;
  int sub_has_rew_runs = 0;
  int sub_has_pun_runs = 0;
  
  //mean and variance of the subject mean, i.e., the group level mean and SD
  group_pr_mu ~ normal(0, 1);
  group_pr_sigma ~ cauchy(0, 5); 
  group_pr_rpdiff_mu ~ normal(0, 1);
  group_pr_rpdiff_sigma ~ cauchy(0, 5);
  alpha_s_pr_sigma ~ cauchy(0, 5);
  //beta_s_pr_sigma ~ cauchy(0, 5);
  lba_k_s_pr_sigma ~ cauchy(0, 5);
  lba_tau_s_pr_sigma ~ cauchy(0, 5);

  //subject level.
  for (s in 1:N){
    alpha_s_pr_mu[s] ~ normal(group_pr_mu[PID_ALPHA],group_pr_sigma[PID_ALPHA]);
    //beta_s_pr_mu[s] ~ normal(group_pr_mu[2],group_pr_sigma[2]);
    lba_k_s_pr_mu[s] ~ normal(group_pr_mu[PID_LBA_K],group_pr_sigma[PID_LBA_K]);
    lba_tau_s_pr_mu[s] ~ normal(group_pr_mu[PID_LBA_TAU],group_pr_sigma[PID_LBA_TAU]);
    
    alpha_s_pr_rpdiff_mu[s] ~ normal(group_pr_rpdiff_mu[PID_ALPHA],group_pr_rpdiff_sigma[PID_ALPHA]); 
    lba_k_s_pr_rpdiff_mu[s] ~ normal(group_pr_rpdiff_mu[PID_LBA_K],group_pr_rpdiff_sigma[PID_LBA_K]); 
    //beta_s_pr_rpdiff_mu[s] ~ normal(group_pr_rpdiff_mu[2],group_pr_rpdiff_sigma[2]); 
    //alpha_s_pr_rpdiff_mu[s] ~ normal(0, 1); 
    //beta_s_pr_rpdiff_mu[s] ~ normal(0, 1); 
    
    //record the kind of runs this subject has
    sub_has_rew_runs = 0;
    sub_has_pun_runs = 0;
    for (r in 1:R){
      if(run_ot[s, r]==1){//1 represents reward
        sub_has_rew_runs = 1;
      }else if (run_ot[s, r]==2){//2 represents punishment
        sub_has_pun_runs = 1;
      }
    }
    
    
    //run level
    for (r in 1:R){
      //remember, because we made the simplifying assumption that every subject has the same run-level variance,
      //we just use the same alpha_s_sigma value for every subject :-)
      
      
      if(sub_has_rew_runs && sub_has_pun_runs){
        //this subject has both reward and punishment runs
        //if this run is a reward run, set the multiplier to 1. 
        //If it's a punishment run, set it to -1.
        if(run_ot[s, r]==1){
          run_ot_multiplier = 0.5;
        }else if (run_ot[s, r]==2){
          run_ot_multiplier = -0.5;
        }
      }else{
        //If this subject doen'st have both reward and punishment runs, set the multiplier to 0.
        run_ot_multiplier = 0;
      }
      
      
      alpha_pr[s,r] ~ normal(alpha_s_pr_mu[s]+run_ot_multiplier*alpha_s_pr_rpdiff_mu[s],alpha_s_pr_sigma);
      lba_k_pr[s,r] ~ normal(lba_k_s_pr_mu[s]+run_ot_multiplier*lba_k_s_pr_rpdiff_mu[s],lba_k_s_pr_sigma);
      lba_tau_pr[s,r] ~ normal(lba_tau_s_pr_mu[s],lba_tau_s_pr_sigma);//we're assuming no difference between reward and punishment here.
      #beta_pr[s,r] ~ normal(beta_s_pr_mu[s]+run_ot_multiplier*beta_s_pr_rpdiff_mu[s],beta_s_pr_sigma);

    }
  }
  
  for (s in 1:N) {
    // Define values
    matrix[100,2] ev;
    real PEnc; // fictitious prediction error (PE-non-chosen)
    real PE;         // prediction error

    // Initialize values
    ev[,1] = rep_vector(0, 100); // initial ev values
    ev[,2] = rep_vector(0, 100); // initial ev values

    for (t in 1:(Tsubj[s])) {
      // compute action probabilities
        // NB: In this algorithm, should exploit the fact that 
        // accumulation of updated values occurs independently for runs and outcome_types, i.e.,
        // no images occur across runs or outcome_types
        
      //get the particular run we are dealing with for this trial.
      run = run_id[s,t]; 
        
      if (choice[s,t]!=0) {#non-response trial.
        if(sample_from_prior!=1){
          #do we need a model simulating time taken here? if it's greater than x delay then we do nothing
          #if it's less than the delay then we act, otherwise we don't.
          #choice[s,t] ~ categorical_logit( to_vector(ev[cue[s,t],]) * beta[s, run] * rt[s,t] );
           //the relative threshold, k; 
           //the maximum starting evidence, A; 
           //a vector holding the drift rates, v; 
           //the standard deviation of the drift rates, s; 
           //and the nondecision time, tau.
           //real lba_log(matrix RT, real k, real A, vector v, real s, real tau){
          #the two values in cue should really approach 0 and 1, respectively.
          //print(to_vector(ev[cue[s,t],]))
          //not sure of the change that ev[cue[s,t],] takes
          //but I think it is [-1, 1]
          //in which case, to transform it using a logit function to [0, Inf] we need
          //logit(seq(-1,1,0.1)/4+0.75)
          //If it's actually [0, 1] then the transformation we need is
          //logit(seq(0,1,0.1)/2+0.5)
          RT_choice[s,,] ~ lba(lba_k[s, run], 0.01, logit(to_vector(ev[cue[s,t],])/4+0.75), 1, lba_tau[s, run]);
          
        
          // prediction error
          PE   =  outcome[s,t] - ev[cue[s,t],choice[s,t]];
          #can't use this as an index because it's not 
          PEnc = -outcome[s,t] - ev[cue[s,t],3-choice[s,t]];
    
          // value updating (learning)
          ev[cue[s,t],3-choice[s,t]] = ev[cue[s,t],3-choice[s,t]] + alpha[s, run] * PEnc;
          ev[cue[s,t],choice[s,t]] = ev[cue[s,t],choice[s,t]] + alpha[s, run] * PE;
        }
        else{
          print("sampling from prior; data ignored.")
        }
      }
    }
  }
}

generated quantities {
  // For group level parameters
  real<lower=0,upper=1> group_mu_alpha;
  real<lower=0,upper=14> group_mu_beta;
  real<lower=0,upper=1> group_sigma_alpha;
  real<lower=0,upper=14> group_sigma_beta;
  
  real<lower=0,upper=1> group_rew_mu_alpha;
  real<lower=0,upper=14> group_rew_mu_beta;
  // real<lower=0,upper=1> group_rew_sigma_alpha;
  // real<lower=0,upper=14> group_rew_sigma_beta;
  
  real<lower=0,upper=1> group_pun_mu_alpha;
  real<lower=0,upper=14> group_pun_mu_beta;
  // real<lower=0,upper=1> group_pun_sigma_alpha;
  // real<lower=0,upper=14> group_pun_sigma_beta;
  
  // vector[N] alpha_s_mu;
  // vector[N] beta_s_mu;
  // real alpha_s_sigma;
  // real beta_s_sigma;
  
  //group level
  group_mu_alpha  = Phi_approx(group_pr_mu[1]);
  group_mu_beta   = Phi_approx(group_pr_mu[2]) * 14;
  group_sigma_alpha  = Phi_approx(group_pr_sigma[1]);
  group_sigma_beta   = Phi_approx(group_pr_sigma[2]) * 14;
  
  group_rew_mu_alpha  = Phi_approx(group_pr_mu[1]+0.5*group_pr_rpdiff_mu[1]);
  group_rew_mu_beta   = Phi_approx(group_pr_mu[2]+0.5*group_pr_rpdiff_mu[2]) * 14;
  
  group_pun_mu_alpha  = Phi_approx(group_pr_mu[1]-0.5*group_pr_rpdiff_mu[1]);
  group_pun_mu_beta   = Phi_approx(group_pr_mu[2]-0.5*group_pr_rpdiff_mu[2]) * 14;

  // if(subj_level_params==1){
  //   //subject level parameters. 
  //   alpha_s_mu = Phi_approx(alpha_s_pr_mu);
  //   beta_s_mu = Phi_approx(beta_s_pr_mu);
  // 
  //   alpha_s_sigma = Phi_approx(alpha_s_pr_sigma);
  //   beta_s_sigma = Phi_approx(beta_s_pr_sigma);
  // }
}
