version="h_m1"
#our first hierarhical model for the reversal learning dataset.
verbose=TRUE
source('de_mcmc/main_m1_setup.R')

##############################################  generate data
source("de_mcmc/raw_data_reward_only.R")

##############################################  initialize
#data[[1]]
#NAMING CONVENTION
#start with the name of the parameter itself (e.g., "alpha", "beta", and so on)
#For bottom levels, ELIMINATE the specific level it refers to. So somewhat paradoxically, for the alpha value for each subject, do NOT append "s", but append any other values (e.g., "run_mu")
#For next level up, specify which distribution it takes an average of (e.g., "alpha_s") then the hyper parameter it is (e.g., mu, sigma)w
#if we treat the levels as LISTS rather than ARRAYS then we can associate arbitrary dimensions to each parameter

#NAMING CONVENTION 2
#start with the name of the parameter itself (e.g., "alpha", "beta", and so on)
#always refer to the specific level, e.g., "run" if this is for the run
#if it's an average of something within a group, then specify both
#e.g., the average across runs for a subject is alpha_r_mu_s
#if it's the conjugate, can eliminate the lower-level values, so that the group-level parameter is "alpha_s_mu"
#otherwise keep, so that we have alpha_r_sigma_s generated by alpha_r_sigma_s_{sigma hypers}
#we might end up with nothing called simply "alpha" but that's OK.
#call the bottom level transformed variable "f_alpha_s" for 'function of alpha_s'
level1.par.names=c("alpha_s",#"beta",
            "thresh_s","tau_s")

level2.par.names<-c(paste0(level1.par.names, "_mu"),paste0(level1.par.names, "_sigma"))

#par.names<-c(level1.par.names,level2.par.names)
n.pars=length(par.names)

n.chains=24
nmc=5000
burnin=1000
thin=1
keep.samples=seq(burnin,nmc,thin)
print(length(keep.samples)*n.chains)


use.optim=TRUE
optim.gamma=TRUE
migrate.prob=.1
migrate.duration=round(burnin*.25)+1
b=.001
  
cores=8
data<-data[seq(1,161,50)]
S=length(data)

#defining initial values
#because this time, these variables will be normal distributions, means can be zero, SDs can be ones.

#MAY NEED TO ADJUST THESE TAU VALUES IN LIGHT OF PUTTING THIS IN NORMAL DISTRIBUTION SPACE
x.init<- list()
x.init[[level1.par.names[[1]] ]]<-rep(0,S)#alpha
x.init[[level1.par.names[[2]] ]]<-rep(2,S)#thresh
x.init[[level1.par.names[[3]] ]]=.6*(sapply(data,function(x)min(x$rt,na.rm=TRUE))) #is this the best we can do?
#mu values
for (pn in level2.par.names[1:2]){
  x.init[[pn]]<-0
}
x.init[[level2.par.names[3]]]=.6*mean(sapply(data,function(x)min(x$rt,na.rm=TRUE))) #is this the best we can do?
#sigma values
for (pn in level2.par.names[4:5]){
  x.init[[pn]]<-1
}
x.init[[level2.par.names[6]]]=.6*sd(sapply(data,function(x)min(x$rt,na.rm=TRUE))) #is this the best we can do?

n.parinstances<-length(unlist(x.init))#the list of parameter instances, counting each element of the vector parameters
parinstancenames<-names(unlist(x.init))
##############################################  set prior

prior=NULL
# upper and lower boundaries for the concentration parameters
prior$lower=0  
prior$upper=1

########################################## run it
source(paste0("de_mcmc/model_configs/de_",version,"_config.R"))
source(paste0("de_mcmc/de_",version,"_run.R"))

run_env<-de_mcmc_execute(log.dens.like.h.m1,log.dens.prior.h.m1)#log.dens.like.f<-log.dens.like.h.m1;log.dens.prior.f<-log.dens.prior.h.m1
attach(run_env)


########################################## estimation
##graphics.  

# plot.lower=TRUE
# plot.weights=TRUE
# start=2
# start.weights=2
# 
# pdf(paste(save.dir,save.name,".pdf",sep=""),10,5)
# par(mfrow=c(1,2),ask=FALSE)
# source("de_mcmc/fig_base.R")
# dev.off()