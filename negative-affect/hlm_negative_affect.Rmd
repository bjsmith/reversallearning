---
title: "Negative affect behavioral data"
output: html_notebook
---
Verifying pain signal

If the NPS similarity reliably measures pain, then we should see that the NPS score is higher in trials where subjects receive an electric shock compared to trials where they do not. Thus, sign that the NPS is measuring pain is to ensure that:

 1. In the punishment runs, NPS scores should be higher in those trials where subjects receive an electric shock than those where they did not, i.e., where they made an incorrect response or made no response compared to when they made a correct response.
 2. The difference between incorrect or non-responses and correct responses should be substantially stronger in the punishments than in the reward runs, where subjects were being rewarded for correct responses, but not punished for incorrect responses. If this is indeed the case, then we have evidence the NPS is measuring the brain response to physical pain. If there is no difference, then the NPS might be detecting non-physical pain, or a negative signal which is not physical pain.

After the NPS scores were obtained, I tested these two postulates with a series of linear models.

```{r, include=FALSE,cache=TRUE}
library(lme4)
library(ggplot2)
library(data.table)
setwd("../")
source("negative-affect/negative_affect_trials_setup.R")

fixedef.se<-function(fit){
  return(summary(fit)$coefficients[,"Std. Error"])
}

require(lme4)
lm.beta.lmer <- function(mod) {
  b <- fixef(mod)[-1]
  sd.x <- apply(getME(mod,"X")[,-1],2,sd)
  sd.y <- sd(getME(mod,"y"))
  b*sd.x/sd.y
}



```

## NPS scores higher in trials where subjects receive an electric shock

The first set of models tests our ability distinguish between punished trials (incorrect or non-response) and non-punished trials (correct results) in the punishment runs.

We first build a base level model, for comparison, that attempts to predict the NPS signal on a given trial without reference to whether or not that trial was correct.


```{r, echo=TRUE}
m.0<-lmer(ValueScaled~
                     presentation_n_in_segment + 
                     (1+presentation_n_in_segment | subid/runmotiveid) + 
                     (1 | image),rawdata.ordered.complete[Motivation=="punishment"])
summary(m.0)
# m.0.nm<-lmer(ValueScaled~
#                      presentation_n_in_segment + 
#                      (1+presentation_n_in_segment | subid/runid) + 
#                      (1 | image),rawdata.ordered.complete, control=lmerControl(optimizer="Nelder_Mead"))
```

We represent subject as $S$, run as $S$, and image as $\iota$; then 

$V=\mathit{PRESENTATION}_{i} + S_{s(i)} + R_{r(s,i)} + \iota_{j(i)} + \epsilon$

```{r, echo=TRUE}
#m.sronly<-lmer(ValueScaled~presentation_n_in_segment+ (1 | subid/runid),rawdata.ordered.complete[Motivation=="punishment"])
#summary(m.sronly)
```


Then we can repeat the model, this time with the correct response included:

$V=\mathit{RESPONSE}_k*\mathit{PRESENTATION}_{i} + S_{s(i, k )} + R_{r(s,i , k )} + \iota_{j(i, k)} + \epsilon$

```{r, echo=TRUE}

#m.withReponseCorrect<-lmer(ValueScaled~ResponseCorrect + presentation_n_in_segment + (1+ResponseCorrect | subid/runid),pain_data)
m.withResponseCorrect<-lmer(ValueScaled~
                     ResponseCorrect + 
                     presentation_n_in_segment + 
                     (1+presentation_n_in_segment | subid/runmotiveid) + 
                     (1 | image),rawdata.ordered.complete[Motivation=="punishment"])
summary(m.withResponseCorrect)


m.withResponseCorrectInteract<-lmer(ValueScaled~
                     ResponseCorrect * 
                     presentation_n_in_segment + 
                     (1+presentation_n_in_segment | subid/runmotiveid) + 
                     (1 | image),rawdata.ordered.complete[Motivation=="punishment"])
summary(m.withResponseCorrectInteract)
```

Over all pain datasets, the model with correct response has much lower AIC and BIC values, incdicating correct response explains variance within the data.


```{r, echo=TRUE}
<<<<<<< HEAD
anova(m.0,m.withResponseCorrect)
=======
anova(m.0,m.withResponseCorrect,m.withResponseCorrectInteract)
>>>>>>> 6f7f50affd0a45d303d41dfec1bb7d98769c6f55
```

This suggests that responses are predictive of the NPS value detected. The beta value estimate representing the response fixed effect suggests that NPS is lower for correct responses (no electric shock) than incorrect responses (electric shock), which is consistent with the purpose of the NPS to measure pain.

This may be the first time that a generalized neurologic pain signal has been connected to an electric shock stimulus.

## Comparison with Reward runs

However, this by itself does not demonstrate that the NPS reponse is in fact directly related to physical pain from the electric shock. Although there are a large number of possible alternative explanations, one plausible explanation is that the NPS signal change is simply that getting an item wrong in the game is affectively unpleasant, even without a direct physical pain. We might posit an ego-driven response to performing well in the task; in effect, an incorrect response is its own punishment.

In order to rule out this possibility, we need to compare the response we get during the punishment runs with a similar response in the reward runs. If we measure the NPS during the Reward task, and compare correct and incorrect responses, do we see the same or a different response? A significantly larger difference in NPS between incorrect and correct responses during hte Reward task seems very unlikely and would likely suggest some methodological error. A main effect difference in the magnitude of the incorrect and correct responses across the Reward and Punishment conditions would suggest the NPS is tracking some kind of punishment signal other than pain. We hope to see a significantly larger difference in NPS between incorrect and correct responses during the Punishment task, and would demonstrate that the signal we find is related to the physical pain of an electric shock. Note that these last two effects could be observed simultaneously, i.e., a main effect and an interaction effect.

We first build a base model that does NOT include information about motives but only whether the trial is correct. Note that the runid used here will index Reward and Punishment runs uniquely, i.e., if the subject has 2 reward and 2 punishment runs, as most do, then runs are numbered from 1 to 4. Here we do include both reward and punishment data.

$V=\mathit{PRESENTATION}_{i} + S_{s(i)} + R_{r(s,i)} + \iota_{j(i)} + \epsilon$

```{r, echo=TRUE}
m.rp.0<-lmer(ValueScaled~
                     (ResponseCorrect==FALSE) + 
                     presentation_n_in_segment + 
                     (1+presentation_n_in_segment | subid/runmotiveid) + 
                     (1 | image),rawdata.ordered.complete)
m.rp<-lmer(ValueScaled~
                     (ResponseCorrect==FALSE)*(Motivation=="punishment") + 
                     presentation_n_in_segment + 
                     (1+presentation_n_in_segment | subid/runmotiveid) + 
                     (1 | image),rawdata.ordered.complete,
           )


m.rp.2<-lmer(ValueScaled~
                     (ResponseCorrect==FALSE)*(Motivation=="punishment") + 
                     presentation_n_in_segment + 
                     (1+presentation_n_in_segment+(ResponseCorrect==FALSE) | subid/runmotiveid) + 
                     (1 | image),rawdata.ordered.complete)

m.rp.contrast<-lmer(ValueScaled~
                     (ResponseCorrect==FALSE)*(Motivation=="punishment") + 
                     presentation_n_in_segment + 
                     (1+ | runmotiveid) + 
                      (1+presentation_n_in_segment+(ResponseCorrect==FALSE):(Motivation=="punishment")  | subid) + 
                     (1 | image),rawdata.ordered.complete)

m.rp.3<-lmer(ValueScaled~
                     (ResponseCorrect==FALSE)*(Motivation=="punishment") + 
                     presentation_n_in_segment + 
                     (1 | runmotiveid) + 
                      (1+presentation_n_in_segment+(ResponseCorrect==FALSE) | subid) + 
                     (1 | image),rawdata.ordered.complete)


```

We can also run an ANOVA and using the result, conduct AIC and BIC tests to see whether overall, model fit was improved by including motivation in the model:

```{r, echo=TRUE, cache=TRUE}
anova(m.rp.0,m.rp)
```

BIC indicates that the model including punishment is strongly predictive.

However the clearest indication of the result here, since we are interested in the direction of an effect, will come from examining the significance and magnitude of the effect sizes of the regressors themselves:

```{r, echo=TRUE}
summary(m.rp.0)
summary(m.rp)
lm.beta.lmer(m.rp)
```

The result:

1. With an estimate of $B=0.094$, $t=9.6$, the interaction of Incorrect Response and Motivation is strong and indicates that there was a brain response to an incorrect outcome in the electric shock punishment condition but not in the reward condition.
2. With an estimate of $B=0.005$, $t=0.66$, the main effect of Incorrect response is not significantly different from zero, which implies the NPS specifically responds to pain feedback and not to negative feedback generally.



```{r, echo=TRUE}
ggplot(rawdata.ordered.complete,aes(y=ValueScaled,x=interaction(ResponseCorrect,Motivation)))+geom_violin()+coord_cartesian(ylim=c(-5,5))

#average valuescaled by subject
rawdata.ordered.complete.dt<-data.table(rawdata.ordered.complete)
data.to.graph<-rawdata.ordered.complete.dt[
  !is.na(ResponseCorrect) & !is.na(Motivation),
  .(ValueScaledBySub=mean(ValueScaled,na.rm=TRUE),ResponseCorrect,Motivation),.(subid,ResponseCorrect,Motivation)]

data.to.graph[,Response:=sapply(ResponseCorrect,function(x){ifelse(x,"Correct","Wrong")})]
data.to.graph$Motivation<-factor(data.to.graph$Motivation,levels=c("reward","punishment"))
ggplot(data.to.graph,
       aes(y=ValueScaledBySub,x=interaction(Response,Motivation),color=interaction(Response,Motivation)))+
  scale_colour_manual(values=c("#888888", "#888888","#888888","#ff0000"),guide=FALSE)+
  geom_violin()+geom_jitter(width=0.3,height=0.0,alpha=0.2)+
  stat_summary(fun.y = mean, geom = "errorbar", aes(ymax = ..y.., ymin = ..y..),
                 width = 2, linetype = "dashed")+
  scale_x_discrete(labels=c("Reward condition\nCORRECT","Reward condition\nWRONG","Punishment condition\nCORRECT","Punishment condition\nWRONG"),
                   name="Condition\nSUBJECT RESPONSE")+
  scale_y_continuous(name="Neurologic Pain Signature Value\n(Subject Mean)")+
  labs(title="Neurologic Pain Signature Value in Reversal learning\nBy Subject Response and Condition")
  
data.to.graph.2<-tidyr::spread(data.to.graph,Motivation,ValueScaledBySub)
data.to.graph.2$PunishmentMinusReward<-data.to.graph.2$punishment-data.to.graph.2$reward


ggplot(data.to.graph.2,
       aes(y=PunishmentMinusReward,x=ResponseCorrect,color=ResponseCorrect))+
  scale_colour_manual(values=c("#ff0000", "#888888", "#888888","#888888"),guide=FALSE)+
  geom_violin()+geom_jitter(width=0.3,height=0.0,alpha=0.2)+
  stat_summary(fun.y = mean, geom = "errorbar", aes(ymax = ..y.., ymin = ..y..),
                 width = 2, linetype = "dashed")+
  scale_x_discrete(labels=c("WRONG","CORRECT"),
                   name="SUBJECT RESPONSE")+
  scale_y_continuous(name="Neurologic Pain Signature Value Punishment Minus Reward\n(Subject Mean)")+
  labs(title="Neurologic Pain Signature Value in Reversal learning\nBy Subject Response and Condition")


data.to.graph.3<-data.to.graph[,ResponseCorrect:=NULL] %>% tidyr::spread(Response,ValueScaledBySub)
data.to.graph.3$WrongMinusCorrect<-data.to.graph.3$Wrong-data.to.graph.3$Correct

ggplot(data.to.graph.3,
       aes(y=WrongMinusCorrect,x=Motivation,color=Motivation))+
  scale_colour_manual(values=c("#ff0000", "#888888", "#888888","#888888"),guide=FALSE)+
  geom_violin()+geom_jitter(width=0.3,height=0.0,alpha=0.2)+
  stat_summary(fun.y = mean, geom = "errorbar", aes(ymax = ..y.., ymin = ..y..),
                 width = 2, linetype = "dashed")+
  #scale_x_discrete(labels=c("WRONG","CORRECT"),
  #                 name="SUBJECT RESPONSE")+
  scale_y_continuous(name="Neurologic Pain Signature Value Punishment Minus Reward\n(Subject Mean)")+
  labs(title="Neurologic Pain Signature Value in Reversal learning\nBy Subject Response and Condition")
```

```{r, echo=TRUE}
lm.beta.lmer(m.rp.0)

```



```{r, echo=TRUE}

```