plot_model(fit)
HDIofMCMC
library(hBayesDM)
HDIofMCMC
fit.extracted<-rstan::extract(fit$fit)
fit.extracted$alpha_rew
dim(fit.extracted$alpha_rew)
HDIofMCMC(fit.extracted$mu_alpha_rew)
ggplot(fit.extracted$mu_alpha_rew)+geom_histogram(bins=10)
learningRateTable<-function(f){rbind(
data.table(
mean=f$mu_beta_rew,
variance=f$sigma[,1,2],mode="reward",Group="RiskyMeth"),
data.table(mean=f$mu_beta_pun,
variance=f$sigma[,2,2],
mode="punishment",Group="RiskyMeth"))
}
inverse.temperature.estimate.g2<-learningRateTable(fit.RiskyNoMeth.extracted)
fit.NoRiskyMeth<-lookupOrRunFit(run=c(1,2),groups_to_fit=2, model_to_use="double_update_rp_repeated_runs",includeSubjGroup = FALSE,
rp=c(REVERSAL_LEARNING_REWARD,REVERSAL_LEARNING_PUNISHMENT),
model_rp_separately=TRUE,model_runs_separately = TRUE, include_pain=FALSE)
fit.RiskyNoMeth.extracted<-rstan::extract(fit.NoRiskyMeth$fit)
HDIofMCMC(fit.RiskyNoMeth.extracted$mu_alpha_rew)
HDIofMCMC(fit.RiskyNoMeth.extracted$mu_beta_rew)
rm(fit)
rm(fit.extracted)
rm(fit.NoRiskyMeth)
rm(fit.RiskyNoMeth.extracted)
source("fitGroupsV3Onegroup.R")
learningRateTable<-function(f){rbind(
data.table(
mean=f$mu_alpha_rew,
variance=f$sigma[,1,2],mode="reward",Group="RiskyMeth"),
data.table(mean=f$mu_alpha_pun,
variance=f$sigma[,2,2],
mode="punishment",Group="RiskyMeth"))
}
inverseTemperatureTable<-function(f){rbind(
data.table(
mean=f$mu_beta_rew,
variance=f$sigma[,1,2],mode="reward",Group="RiskyMeth"),
data.table(mean=f$mu_beta_pun,
variance=f$sigma[,2,2],
mode="punishment",Group="RiskyMeth"))
}
fit.RiskyNoMeth<-lookupOrRunFit(run=c(1,2),groups_to_fit=2, model_to_use="double_update_rp_repeated_runs",includeSubjGroup = FALSE,
rp=c(REVERSAL_LEARNING_REWARD,REVERSAL_LEARNING_PUNISHMENT),
model_rp_separately=TRUE,model_runs_separately = TRUE, include_pain=FALSE)
fit.RiskyNoMeth.ex<-rstan::extract(fit.RiskyNoMeth$fit)
rm(fit.NoRiskyMeth)#these are large files; let's not keep them in memory where unnecessary.
learning.rate.estimate.g2<-learningRateTable(fit.RiskyNoMeth.ex)
inverse.temperature.estimate.g2<-inverseTemperatureTable(fit.RiskyNoMeth.ex)
#rm(fit.RiskyNoMeth.ex)
fit.RiskyMeth<-lookupOrRunFit(run=c(1,2),groups_to_fit=3, model_to_use="double_update_rp_repeated_runs",includeSubjGroup = FALSE,
rp=c(REVERSAL_LEARNING_REWARD,REVERSAL_LEARNING_PUNISHMENT),
model_rp_separately=TRUE,model_runs_separately = TRUE, include_pain=FALSE)
fit.RiskyMeth.ex<-rstan::extract(fit.RiskyMeth$fit)
rm(fit.RiskyMeth)#these are large files; let's not keep them in memory where unnecessary.
learning.rate.estimate.g3<-learningRateTable(fit.RiskyNoMeth.ex)
inverse.temperature.estimate.g3<-inverseTemperatureTable(fit.RiskyNoMeth.ex)
#rm(fit.RiskyMeth.ex)
learning.rate.estimate<-rbind(learning.rate.estimate.g2,learning.rate.estimate.g3)
inverse.temperature.estimate<-rbind(inverse.temperature.estimate.g2,inverse.temperature.estimate.g3)
ggplot(learning.rate.estimate,aes(x=mean,y=variance,colour=Group))+geom_point()+
facet_grid(.~mode)+
labs(title="Posterior group-level learning rate and variance for reward and punishment\n(Both Runs)")
ggplot(inverse.temperature.estimate,aes(x=mean,y=variance,colour=Group))+geom_point()+
facet_grid(.~mode)+
labs(title="Posterior group-level inverse temperature and variance for reward and punishment\n(Both Runs)")
fit.RiskyNoMeth.ex<-rstan::extract(fit.RiskyNoMeth$fit)
rm(fit.NoRiskyMeth)#these are large files; let's not keep them in memory where unnecessary.
rm(fit.RiskyMeth.ex)
rm(fit.RiskyNoMeth)
rm(fit.RiskyNoMeth.ex)
source("fitGroupsV3Onegroup.R")
learningRateTable<-function(f){rbind(
data.table(
mean=f$mu_alpha_rew,
variance=f$sigma[,1,2],mode="reward",Group="RiskyMeth"),
data.table(mean=f$mu_alpha_pun,
variance=f$sigma[,2,2],
mode="punishment",Group="RiskyMeth"))
}
inverseTemperatureTable<-function(f){rbind(
data.table(
mean=f$mu_beta_rew,
variance=f$sigma[,1,2],mode="reward",Group="RiskyMeth"),
data.table(mean=f$mu_beta_pun,
variance=f$sigma[,2,2],
mode="punishment",Group="RiskyMeth"))
}
fit.RiskyNoMeth<-lookupOrRunFit(run=c(1,2),groups_to_fit=2, model_to_use="double_update_rp_repeated_runs",includeSubjGroup = FALSE,
rp=c(REVERSAL_LEARNING_REWARD,REVERSAL_LEARNING_PUNISHMENT),
model_rp_separately=TRUE,model_runs_separately = TRUE, include_pain=FALSE)
fit.RiskyNoMeth.ex<-rstan::extract(fit.RiskyNoMeth$fit)
rm(fit.RiskyNoMeth.ex)#these are large files; let's not keep them in memory where unnecessary.
learning.rate.estimate.g2<-learningRateTable(fit.RiskyNoMeth.ex)
source("fitGroupsV3Onegroup.R")
learningRateTable<-function(f){rbind(
data.table(
mean=f$mu_alpha_rew,
variance=f$sigma[,1,2],mode="reward",Group="RiskyMeth"),
data.table(mean=f$mu_alpha_pun,
variance=f$sigma[,2,2],
mode="punishment",Group="RiskyMeth"))
}
inverseTemperatureTable<-function(f){rbind(
data.table(
mean=f$mu_beta_rew,
variance=f$sigma[,1,2],mode="reward",Group="RiskyMeth"),
data.table(mean=f$mu_beta_pun,
variance=f$sigma[,2,2],
mode="punishment",Group="RiskyMeth"))
}
fit.RiskyNoMeth<-lookupOrRunFit(run=c(1,2),groups_to_fit=2, model_to_use="double_update_rp_repeated_runs",includeSubjGroup = FALSE,
rp=c(REVERSAL_LEARNING_REWARD,REVERSAL_LEARNING_PUNISHMENT),
model_rp_separately=TRUE,model_runs_separately = TRUE, include_pain=FALSE)
fit.RiskyNoMeth.ex<-rstan::extract(fit.RiskyNoMeth$fit)
rm(fit.RiskyNoMeth)#these are large files; let's not keep them in memory where unnecessary.
learning.rate.estimate.g2<-learningRateTable(fit.RiskyNoMeth.ex)
inverse.temperature.estimate.g2<-inverseTemperatureTable(fit.RiskyNoMeth.ex)
fit.RiskyMeth<-lookupOrRunFit(run=c(1,2),groups_to_fit=3, model_to_use="double_update_rp_repeated_runs",includeSubjGroup = FALSE,
rp=c(REVERSAL_LEARNING_REWARD,REVERSAL_LEARNING_PUNISHMENT),
model_rp_separately=TRUE,model_runs_separately = TRUE, include_pain=FALSE)
fit.RiskyMeth.ex<-rstan::extract(fit.RiskyMeth$fit)
rm(fit.RiskyMeth)#these are large files; let's not keep them in memory where unnecessary.
learning.rate.estimate.g3<-learningRateTable(fit.RiskyNoMeth.ex)
inverse.temperature.estimate.g3<-inverseTemperatureTable(fit.RiskyNoMeth.ex)
learning.rate.estimate<-rbind(learning.rate.estimate.g2,learning.rate.estimate.g3)
inverse.temperature.estimate<-rbind(inverse.temperature.estimate.g2,inverse.temperature.estimate.g3)
ggplot(learning.rate.estimate,aes(x=mean,y=variance,colour=Group))+geom_point()+
facet_grid(.~mode)+
labs(title="Posterior group-level learning rate and variance for reward and punishment\n(Both Runs)")
ggplot(inverse.temperature.estimate,aes(x=mean,y=variance,colour=Group))+geom_point()+
facet_grid(.~mode)+
labs(title="Posterior group-level inverse temperature and variance for reward and punishment\n(Both Runs)")
getwd()
apply_local_settings()
source("util/apply_local_settings.R")
apply_local_settings()
source("util/configure_local_settings.R")
configure_local_settings()
source("util/configure_local_settings.R")
configure_local_settings()
apply_local_settings()
getwd()
knitr::opts_chunk$set(echo = TRUE)
library(data.table)
library(rstan)
install.packages(rstan)
install.packages("rstan")
plot(1:10)
plot(1:10)
library(ggplot2)
ggplot(data.frame("a"=1:10,"b"=(1:10)^2))
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = TRUE)
library(data.table)
library(rstan)
library(ggplot2)
source("fitGroupsV3Onegroup.R")
install.packages("loo")
source("fitGroupsV3Onegroup.R")
install.packages("pROC")
library(pROC)
source("fitGroupsV3Onegroup.R")
learningRateTable<-function(f){rbind(
data.table(
mean=f$mu_alpha_rew,
variance=f$sigma[,1,2],mode="reward",Group="RiskyMeth"),
data.table(mean=f$mu_alpha_pun,
variance=f$sigma[,2,2],
mode="punishment",Group="RiskyMeth"))
}
inverseTemperatureTable<-function(f){rbind(
data.table(
mean=f$mu_beta_rew,
variance=f$sigma[,1,2],mode="reward",Group="RiskyMeth"),
data.table(mean=f$mu_beta_pun,
variance=f$sigma[,2,2],
mode="punishment",Group="RiskyMeth"))
}
fit.RiskyNoMeth<-lookupOrRunFit(
run=c(1,2),groups_to_fit=2, model_to_use="double_update_rp_repeated_runs",includeSubjGroup = FALSE,
rp=c(REVERSAL_LEARNING_REWARD,REVERSAL_LEARNING_PUNISHMENT),
model_rp_separately=TRUE,model_runs_separately = TRUE, include_pain=FALSE)
fit.RiskyNoMeth.ex<-rstan::extract(fit.RiskyNoMeth$fit)
rm(fit.RiskyNoMeth)#these are large files; let's not keep them in memory where unnecessary.
learning.rate.estimate.g2<-learningRateTable(fit.RiskyNoMeth.ex)
inverse.temperature.estimate.g2<-inverseTemperatureTable(fit.RiskyNoMeth.ex)
fit.RiskyMeth<-lookupOrRunFit(run=c(1,2),groups_to_fit=3, model_to_use="double_update_rp_repeated_runs",includeSubjGroup = FALSE,
rp=c(REVERSAL_LEARNING_REWARD,REVERSAL_LEARNING_PUNISHMENT),
model_rp_separately=TRUE,model_runs_separately = TRUE, include_pain=FALSE)
fit.RiskyMeth.ex<-rstan::extract(fit.RiskyMeth$fit)
rm(fit.RiskyMeth)#these are large files; let's not keep them in memory where unnecessary.
learning.rate.estimate.g3<-learningRateTable(fit.RiskyNoMeth.ex)
inverse.temperature.estimate.g3<-inverseTemperatureTable(fit.RiskyNoMeth.ex)
learning.rate.estimate<-rbind(learning.rate.estimate.g2,learning.rate.estimate.g3)
inverse.temperature.estimate<-rbind(inverse.temperature.estimate.g2,inverse.temperature.estimate.g3)
ggplot(learning.rate.estimate,aes(x=mean,y=variance,colour=Group))+geom_point()+
facet_grid(.~mode)+
labs(title="Posterior group-level learning rate and variance for reward and punishment\n(Both Runs)")
ggplot(data.frame("a"=1:10,"b"=(1:10)^2))
ggplot(data.frame("a"=1:10,"b"=(1:10)^2))+geom_point()
ggplot(data.frame("a"=1:10,"b"=(1:10)^2),aes(x=a,y=b))+geom_point()
ggplot(learning.rate.estimate,aes(x=mean,y=variance,colour=Group))+geom_point()+
facet_grid(.~mode)+
labs(title="Posterior group-level learning rate and variance for reward and punishment\n(Both Runs)")
ggplot(inverse.temperature.estimate,aes(x=mean,y=variance,colour=Group))+geom_point()+
facet_grid(.~mode)+
labs(title="Posterior group-level inverse temperature and variance for reward and punishment\n(Both Runs)")
ggplot(data.frame("a"=1:10,"b"=(1:10)^2),aes(x=a,y=b))+geom_point()
ggplot(data.frame("a"=1:10,"b"=(1:10)^2),aes(x=a,y=b))+geom_point()+labs(x="x",y="y")
plot(1:100)
plot(1:100)
plot(1:100)
warnings()
plot(1:10)
warnings()
/usr/lib/x86_64-linux-gnu/libpng12.so.0: version `PNG12_0' not found
plot(1:10)
warnings()
plot(1:10)
warnings()
plot(1:10)
sample
sample(2)
sample(10)
sample(10,1)
sample(.Machine$integer.max,1)
source('/expdata/bensmith/joint-modeling/code/msm/behavioral-analysis/reversallearning/try_simple_MCMC.R')
source("nate_files/fitGroupsV3Onegroup.R")
source('/expdata/bensmith/joint-modeling/code/msm/behavioral-analysis/reversallearning/try_simple_MCMC.R')
source('/expdata/bensmith/joint-modeling/code/msm/behavioral-analysis/reversallearning/try_simple_MCMC.R')
options(mc.cores = ceiling(parallel::detectCores()/2))
ceiling(parallel::detectCores()/2)
source('/expdata/bensmith/joint-modeling/code/msm/behavioral-analysis/reversallearning/try_simple_MCMC.R')
print(sessionInfo())
install.packages("GGally")
install.packages("RColorBrewer")
knitr::opts_chunk$set(echo = TRUE)
source("../nate_files/fitGroupsV3Onegroup.R")
source("../data_summarize.R")
library(GGally)
names(s)
s<-model.summaries[[1]]
knitr::opts_chunk$set(echo = TRUE)
source("../nate_files/fitGroupsV3Onegroup.R")
source("../data_summarize.R")
models_to_run<-c("double_update_rpo_repeated_runs","double_update_rp_fixed","double_update_rp_erroneous","double_update")
times_to_run=3
if(file.exists("model-summaries.RData")){
load(file="model-summaries.RData")
}else{
model.summaries <- vector("list", 2*length(models_to_run)*times_to_run)
}
if(any(sapply(model.summaries,is.null))){
for (g in 2:3){
for (m in models_to_run){
for (t in 1:times_to_run){
print (paste0(g,m,t,collapse=", "))
#only run reward and punishment when we can
if(models_to_run %in% c("double_update_rpo_repeated_runs","double_update_rp_fixed","double_update_rp_erroneous")){
rp<-c(1,2)
}else{
rp<-c(2)
}
#only run multiple runs when we can
if(models_to_run %in% c("double_update_rpo_repeated_runs")){
runs=c(1,2)
generatePosteriorTrialPredictions=FALSE
}else{
runs=c(1)
generatePosteriorTrialPredictions=NA
}
#run the model
fit<-lookupOrRunFit(
run=runs,groups_to_fit=g, model_to_use=m,includeSubjGroup = FALSE,
rp=rp,
model_rp_separately=TRUE,model_runs_separately = TRUE, include_pain=FALSE,
fileSuffix=paste0("20170923_test_iteration_",as.character(t),generatePosteriorTrialPredictions=generatePosteriorTrialPredictions)
)
cat("...model loaded. Extracting...")
#save just the output we want.
first_empty_list_pos<-min(which(sapply(model.summaries,is.null)))
print(paste("first_empty_list_pos is", as.character(first_empty_list_pos)))
if(m=="double_update_rpo_repeated_runs"){
model.summaries[[first_empty_list_pos]]<-
list("summaryObj"=data_summarize_double_update_rpo_repeated_runs(rstan::extract(fit$fit)),
"g"=g,"m"=m,"t"=t)
}else if(m=="double_update_rp_erroneous" || m=="double_update_rp_fixed"){
model.summaries[[first_empty_list_pos]]<-
list("summaryObj"=data_summarize_double_update_rp(rstan::extract(fit$fit),
run = runs),
"g"=g,"m"=m,"t"=t)
}else if(m=="double_update"){
model.summaries[[first_empty_list_pos]]<-
list("summaryObj"=data_summarize_double_update(rstan::extract(fit$fit),
outcome.type = rp,
run = runs),
"g"=g,"m"=m,"t"=t)
}else{
stop("f^<%! I don't recognize that model.")
}
#remove the fit object from memory, because it is pretty large!
rm(fit)
print("...summary data extracted.")
}
}
}
save(model.summaries,file="model-summaries.RData")
}
#arrange all the data into a single data table.
model.summary.all<-NULL
for(ms in model.summaries){
ms.summaryObj<-ms$summaryObj
ms.summaryObj$Group<-ms$g
ms.summaryObj$ModelName<-ms$m
ms.summaryObj$AnalysisRepetition<-ms$t
if(is.null(model.summary.all)){
model.summary.all<-ms.summaryObj
}else{
model.summary.all<-rbind(model.summary.all,ms.summaryObj)
}
}
m.run1.punish.alpha.mu<-model.summary.all[Motivation=="Reward" & Statistic=="mu" & Parameter=="alpha" & Run==1]
#nice.
#now, we should be able to ask how much of the variance is due to AnalysisRepetition, how much is due to Group, how much is due to ModelName
#to keep things simple we will start with mu-alpha, run1, and treat iteration as random variable
var.res.alpha<-aov(Value~factor(AnalysisRepetition)+factor(Group)+ModelName,m.run1.punish.alpha.mu)
print(summary(var.res.alpha))
print(drop1(var.res.alpha,~.,test="F"))
m.run1.punish.beta.mu<-model.summary.all[Motivation=="Reward" & Statistic=="mu" & Parameter=="beta" & Run==1]
#nice.
#now, we should be able to ask how much of the variance is due to AnalysisRepetition, how much is due to Group, how much is due to ModelName
#to keep things simple we will start with mu-alpha, run1, and treat iteration as random variable
var.res.beta<-aov(Value~factor(AnalysisRepetition)+factor(Group)+ModelName,m.run1.punish.beta.mu)
print(summary(var.res.beta))
print(drop1(var.res.beta,~.,test="F"))
source("../visualization/geom_hdi.R")
m.reward.mu.run1<-model.summary.all[Motivation=="Reward" & Statistic=="mu" & Run==1]
#table(m.reward.mu.run1$ModelName)
#for clarity's sake...
m.reward.mu.run1$ModelName<-sub("double_update","DU",m.reward.mu.run1$ModelName)
#plotly::ggplotly(p)
ggplot(m.reward.mu.run1[Parameter=="alpha"],aes(x=Value,fill=factor(Group),color=factor(Group)))+
geom_freqpoly(alpha=0.9,binwidth=0.001)+
geom_hdi(size=2, lineend = "round",alpha=0.5,credible_mass=0.95)+
facet_grid(ModelName~AnalysisRepetition)+
labs(title=paste0("mu statistic in reward rounds, alpha"))
ggplot(m.reward.mu.run1[Parameter=="beta"],aes(x=Value,fill=factor(Group),color=factor(Group)))+
geom_freqpoly(alpha=0.9,binwidth=0.001)+
geom_hdi(size=2, lineend = "round",alpha=0.9,credible_mass=0.95)+
facet_grid(ModelName~AnalysisRepetition)+
labs(title=paste0("mu statistic in reward rounds, beta"))
alpha_lastModel<-tidyr::spread(m.reward.mu.run1[Parameter=="alpha" & ModelName=="DU_rpo_repeated_runs"],
Group, Value)
alpha_lastModel$GroupDifference<-alpha_lastModel$`2`-alpha_lastModel$`3`
plotly::ggplotly(ggplot(alpha_lastModel,
aes(x=GroupDifference,color=factor(AnalysisRepetition)))+
geom_freqpoly(alpha=0.9,binwidth=0.001)+
geom_hdi(size=2,lineend = "round",alpha=0.5,credible_mass=0.95)+
labs(title="learning rate NoMeth-Meth group difference credible values, by Analysis\nWith 95% Highest Density Intervals"))
s<-model.summaries[[1]]
names(s)
names(s[["summaryObj"]]
)
colnames(data.table::dcast(data = s[["summaryObj"]],
Run~Motivation
))
colnames(data.table::dcast(data = s[["summaryObj"]],
iter~Motivation+Run
))
colnames(data.table::dcast(data = s[["summaryObj"]],
iter~Motivation+Run+Statistic+Parameter,
value.var=Value
))
colnames(data.table::dcast(data = s[["summaryObj"]],
iter~Motivation+Run+Statistic+Parameter,
value.var="Value"
))
s.wide<-data.table::dcast(data = s[["summaryObj"]],
iter~Motivation+Run+Statistic+Parameter,
value.var="Value"
)
ggpairs(s.wide)
dim(s.wide)
ggpairs(s.wide[,2:9])
cormat <- round(cor(s.wide),2)
cormat
melted_cormat <- melt(cormat)
ggplot(data = melted_cormat, aes(x=Var1, y=Var2, fill=value)) +
geom_tile()
source("../visualization/gg_labelledcormap.R")
gg_labelledcormap(s.wide)
library(GGally)
gg_labelledcormap(s.wide)
source("../visualization/gg_labelledcormap.R")
source("../visualization/gg_labelledcormap.R")
gg_labelledcormap(s.wide)
source("../visualization/gg_labelledcormap.R")
gg_labelledcormap(s.wide)
source("../visualization/gg_labelledcormap.R")
source("../visualization/gg_labelledcormap.R")
gg_labelledcormap(s.wide)
source("../visualization/gg_labelledcormap.R")
gg_labelledcormap(s.wide)
source("../visualization/gg_labelledcormap.R")
gg_labelledcormap(s.wide)
source("../visualization/gg_labelledcormap.R")
gg_labelledcormap(s.wide)
source("../visualization/gg_labelledcormap.R")
gg_labelledcormap(s.wide)
source("../visualization/gg_labelledcormap.R")
gg_labelledcormap(s.wide)
gg_labelledcormap(s.wide,paste0(s$g,s$m,s$t))
source("../visualization/gg_labelledcormap.R")
gg_labelledcormap(s.wide,paste0(s$g,s$m,s$t))
library(GGally)
source("../visualization/gg_labelledcormap.R")
#model.summary.all[ModelName=="double_update" & AnalysisRepetition==1 & Motivation=="Reward" & Statistic=="mu" & Parameter=="alpha" & ]
for (s in model.summaries){
#s<-model.summaries[[1]]
names(s)
names(s[["summaryObj"]])
s.wide<-data.table::dcast(data = s[["summaryObj"]],
iter~Motivation+Run+Statistic+Parameter,
value.var="Value"
)
gg_labelledcormap(s.wide,paste0("Group ",s$g,", ", s$m,"\nAttempt ",s$t))
}
library(GGally)
source("../visualization/gg_labelledcormap.R")
#model.summary.all[ModelName=="double_update" & AnalysisRepetition==1 & Motivation=="Reward" & Statistic=="mu" & Parameter=="alpha" & ]
for (s in model.summaries){
#s<-model.summaries[[1]]
s.wide<-data.table::dcast(data = s[["summaryObj"]],
iter~Motivation+Run+Statistic+Parameter,
value.var="Value"
)
gg_labelledcormap(s.wide,paste0("Group ",s$g,", ", s$m,"\nAttempt ",s$t))
}
source("../visualization/gg_labelledcormap.R")
gg_labelledcormap(s.wide,paste0("Group ",s$g,", ", s$m,"\nAttempt ",s$t))
source("../visualization/gg_labelledcormap.R")
gg_labelledcormap(s.wide,paste0("Group ",s$g,", ", s$m,"\nAttempt ",s$t))
source("../visualization/gg_labelledcormap.R")
gg_labelledcormap(s.wide,paste0("Group ",s$g,", ", s$m,"\nAttempt ",s$t))
#library(GGally)
source("../visualization/gg_labelledcormap.R")
#model.summary.all[ModelName=="double_update" & AnalysisRepetition==1 & Motivation=="Reward" & Statistic=="mu" & Parameter=="alpha" & ]
for (s in model.summaries){
#s<-model.summaries[[1]]
s.wide<-data.table::dcast(data = s[["summaryObj"]],
iter~Motivation+Run+Statistic+Parameter,
value.var="Value"
)
gg_labelledcormap(s.wide,paste0("Group ",s$g,", ", s$m,"\nAttempt ",s$t))
}
#library(GGally)
source("../visualization/gg_labelledcormap.R")
#model.summary.all[ModelName=="double_update" & AnalysisRepetition==1 & Motivation=="Reward" & Statistic=="mu" & Parameter=="alpha" & ]
for (s in model.summaries){
#s<-model.summaries[[1]]
s.wide<-data.table::dcast(data = s[["summaryObj"]],
iter~Motivation+Run+Statistic+Parameter,
value.var="Value"
)
gg_labelledcormap(s.wide,paste0("Group ",s$g,", ", s$m,"\nAttempt ",s$t))
plot(1:10)
}
#library(GGally)
source("../visualization/gg_labelledcormap.R")
#model.summary.all[ModelName=="double_update" & AnalysisRepetition==1 & Motivation=="Reward" & Statistic=="mu" & Parameter=="alpha" & ]
for (s in model.summaries){
#s<-model.summaries[[1]]
s.wide<-data.table::dcast(data = s[["summaryObj"]],
iter~Motivation+Run+Statistic+Parameter,
value.var="Value"
)
g<-gg_labelledcormap(s.wide,paste0("Group ",s$g,", ", s$m,"\nAttempt ",s$t))
g
}
source("../visualization/gg_labelledcormap.R")
#library(GGally)
source("../visualization/gg_labelledcormap.R")
#model.summary.all[ModelName=="double_update" & AnalysisRepetition==1 & Motivation=="Reward" & Statistic=="mu" & Parameter=="alpha" & ]
for (s in model.summaries){
#s<-model.summaries[[1]]
s.wide<-data.table::dcast(data = s[["summaryObj"]],
iter~Motivation+Run+Statistic+Parameter,
value.var="Value"
)
g<-gg_labelledcormap(s.wide,paste0("Group ",s$g,", ", s$m,"\nAttempt ",s$t))
g
}
#library(GGally)
source("../visualization/gg_labelledcormap.R")
#model.summary.all[ModelName=="double_update" & AnalysisRepetition==1 & Motivation=="Reward" & Statistic=="mu" & Parameter=="alpha" & ]
for (s in model.summaries){
#s<-model.summaries[[1]]
s.wide<-data.table::dcast(data = s[["summaryObj"]],
iter~Motivation+Run+Statistic+Parameter,
value.var="Value"
)
g<-gg_labelledcormap(s.wide,paste0("Group ",s$g,", ", s$m,"\nAttempt ",s$t))
print(g)
}
knit_with_parameters('/expdata/bensmith/joint-modeling/code/msm/behavioral-analysis/reversallearning/notebooks/compare_models.Rmd')
source('~/GDrive/joint-modeling/reversal-learning/behavioral-analysis/reversallearning/write_rewpun_comparer_no_pres.R')
source('~/GDrive/joint-modeling/reversal-learning/behavioral-analysis/reversallearning/rl_behav_analysis_learning_setup.R')
source('~/GDrive/joint-modeling/reversal-learning/behavioral-analysis/reversallearning/write_rewpun_comparer_no_pres.R')
