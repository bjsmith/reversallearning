---
title: "Reversal learning Kruschke-inspired model"
author: "Ben Smith"
date: "10/31/2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Reversal learning

I am thinking about throwing out my existing model, going back perhaps to the last double-update model from Nate and building up from there.

Now that I've read more Kruschke, I have a better idea of how I think I'd do this. So, let's pseudocode it.

At the first level, we are estimating $\alpha$ and $\beta$ parameters for each subject.

Here's where I think Nate does this differently from Kruschke; Nate estimates the subject-levels means and standard deviations constructed algebraically from group means and group sigmas multiplied by individual parameters, Kruschke would model subject means as functions of group means and a sigma of group means, within the model.

So each $\alpha_i$ and $\beta_i$ is drawn from a population-level distribution which has means $\mu_{\alpha}$ and $\mu_{\beta}$ and variances $\sigma_{\alpha}$ and $\sigma_{beta}$. As we are doing this, I need to make sure I've left enough variance to account for population-level variance and not just sample variance. 

I think that is all we need to estimate parameters for the model itself.

But we will want to extend the model to deal with:
 - within-subject variance across 2 2-level factors, Run and Motivation. Run is ordinal-level data (though there's only two of them and we can model it just the same as nominal data) and Motivation is nominal data.
 - between-subject variance, estimating across the three groups. This is still optional. It might be easiest to just estimate the model separately for each group and only pool the variance across groups later. But in theory, we'd get more power using a full model that pools variance across groups.
 
The three groups could be modeled with a single three-level factor.

With these considerations in mind, what actual parameters will we need to model here? Let's list them from bottom to top:

 - Subject-level $\alpha_i$ and $\beta_i$. Each of those are from distributions with $\mu_{\alpha}$ and $\mu_{\beta}$ and variances $\sigma_{\alpha}$ and $\sigma_{beta}$. Consider using student's t distribution rather than a normal distribution to better model population-level variance (See Kruschke 2014, p458; this recommends student's t for a different reason).
 - Using Kruschke's factorial ANOVA design, $\mu_{\alpha}, \mu_{\beta}$ are each calculated from sums of intercepts $\beta_0$, coefficients $\beta_m$ representing Motivation (reward vs. punishment) and $\beta_r$ representing run. Technically $\beta_r$ should be an ordinal parameter but as there are only two runs it doesn't make any difference whether we consider it ordinal or nominal.
 - Each of those $\beta$ coefficients should be estimated from appropriate distributions. $\beta_0$ is drawn from a distribution with a mean equal to the *actual* population mean; we can call it $\mu_{beta_0}$. This is going to be a problem, because we don't actually know the mean learning rate and inverse temperature it in advance; we might have to estimate the distribution from which $\beta_0$ comes, which will legnthen our estimation time but will give us more flexibility. $\beta_m, \beta_r$ are estimated from distributions with a mean of 0 and a standard deviation of 1. Ther will be need to be some extra magic here because we need to implement $\beta$s as functions of $\alpha$s which have had a sum-to-zero transformation applied (see Kruschke, 2014, p556).
 - That gives us our basic model! From there, we could add another level describing Subject Group, following guidelines in Kruschke (2014, chapter 19) for predicting a metric variable with one nominal predictor. If we wanted to ignore interaction effects with reward and punishment, perhaps we could simply estimate $\beta_0$ from separate distributions from each group. We would apply Kruschke's model for $n$ groups as we did at the previous level. The value $\mu_{beta_0}$ from the previous level calculated from a value $\beta_0$ plus the sum of the dot product of the group indicator vector and values for each group. 

```{r cars}
summary(cars)
```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
